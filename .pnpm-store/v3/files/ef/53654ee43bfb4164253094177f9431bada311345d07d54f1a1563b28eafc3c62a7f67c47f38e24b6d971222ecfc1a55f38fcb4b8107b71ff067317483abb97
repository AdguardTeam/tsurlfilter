'use strict';

var path = require('path');
var fs = require('fs');

function Diff() {}
Diff.prototype = {
  diff(oldString, newString, options = {}) {
    let callback = options.callback;
    if (typeof options === 'function') {
      callback = options;
      options = {};
    }
    this.options = options;
    let self = this;
    function done(value) {
      if (callback) {
        setTimeout(function() { callback(undefined, value); }, 0);
        return true;
      } else {
        return value;
      }
    }
    oldString = this.castInput(oldString);
    newString = this.castInput(newString);
    oldString = this.removeEmpty(this.tokenize(oldString));
    newString = this.removeEmpty(this.tokenize(newString));
    let newLen = newString.length, oldLen = oldString.length;
    let editLength = 1;
    let maxEditLength = newLen + oldLen;
    if(options.maxEditLength) {
      maxEditLength = Math.min(maxEditLength, options.maxEditLength);
    }
    let bestPath = [{ oldPos: -1, lastComponent: undefined }];
    let newPos = this.extractCommon(bestPath[0], newString, oldString, 0);
    if (bestPath[0].oldPos + 1 >= oldLen && newPos + 1 >= newLen) {
      return done([{value: this.join(newString), count: newString.length}]);
    }
    let minDiagonalToConsider = -Infinity, maxDiagonalToConsider = Infinity;
    function execEditLength() {
      for (
        let diagonalPath = Math.max(minDiagonalToConsider, -editLength);
        diagonalPath <= Math.min(maxDiagonalToConsider, editLength);
        diagonalPath += 2
      ) {
        let basePath;
        let removePath = bestPath[diagonalPath - 1],
            addPath = bestPath[diagonalPath + 1];
        if (removePath) {
          bestPath[diagonalPath - 1] = undefined;
        }
        let canAdd = false;
        if (addPath) {
          const addPathNewPos = addPath.oldPos - diagonalPath;
          canAdd = addPath && 0 <= addPathNewPos && addPathNewPos < newLen;
        }
        let canRemove = removePath && removePath.oldPos + 1 < oldLen;
        if (!canAdd && !canRemove) {
          bestPath[diagonalPath] = undefined;
          continue;
        }
        if (!canRemove || (canAdd && removePath.oldPos + 1 < addPath.oldPos)) {
          basePath = self.addToPath(addPath, true, undefined, 0);
        } else {
          basePath = self.addToPath(removePath, undefined, true, 1);
        }
        newPos = self.extractCommon(basePath, newString, oldString, diagonalPath);
        if (basePath.oldPos + 1 >= oldLen && newPos + 1 >= newLen) {
          return done(buildValues(self, basePath.lastComponent, newString, oldString, self.useLongestToken));
        } else {
          bestPath[diagonalPath] = basePath;
          if (basePath.oldPos + 1 >= oldLen) {
            maxDiagonalToConsider = Math.min(maxDiagonalToConsider, diagonalPath - 1);
          }
          if (newPos + 1 >= newLen) {
            minDiagonalToConsider = Math.max(minDiagonalToConsider, diagonalPath + 1);
          }
        }
      }
      editLength++;
    }
    if (callback) {
      (function exec() {
        setTimeout(function() {
          if (editLength > maxEditLength) {
            return callback();
          }
          if (!execEditLength()) {
            exec();
          }
        }, 0);
      }());
    } else {
      while (editLength <= maxEditLength) {
        let ret = execEditLength();
        if (ret) {
          return ret;
        }
      }
    }
  },
  addToPath(path, added, removed, oldPosInc) {
    let last = path.lastComponent;
    if (last && last.added === added && last.removed === removed) {
      return {
        oldPos: path.oldPos + oldPosInc,
        lastComponent: {count: last.count + 1, added: added, removed: removed, previousComponent: last.previousComponent }
      };
    } else {
      return {
        oldPos: path.oldPos + oldPosInc,
        lastComponent: {count: 1, added: added, removed: removed, previousComponent: last }
      };
    }
  },
  extractCommon(basePath, newString, oldString, diagonalPath) {
    let newLen = newString.length,
        oldLen = oldString.length,
        oldPos = basePath.oldPos,
        newPos = oldPos - diagonalPath,
        commonCount = 0;
    while (newPos + 1 < newLen && oldPos + 1 < oldLen && this.equals(newString[newPos + 1], oldString[oldPos + 1])) {
      newPos++;
      oldPos++;
      commonCount++;
    }
    if (commonCount) {
      basePath.lastComponent = {count: commonCount, previousComponent: basePath.lastComponent};
    }
    basePath.oldPos = oldPos;
    return newPos;
  },
  equals(left, right) {
    if (this.options.comparator) {
      return this.options.comparator(left, right);
    } else {
      return left === right
        || (this.options.ignoreCase && left.toLowerCase() === right.toLowerCase());
    }
  },
  removeEmpty(array) {
    let ret = [];
    for (let i = 0; i < array.length; i++) {
      if (array[i]) {
        ret.push(array[i]);
      }
    }
    return ret;
  },
  castInput(value) {
    return value;
  },
  tokenize(value) {
    return value.split('');
  },
  join(chars) {
    return chars.join('');
  }
};
function buildValues(diff, lastComponent, newString, oldString, useLongestToken) {
  const components = [];
  let nextComponent;
  while (lastComponent) {
    components.push(lastComponent);
    nextComponent = lastComponent.previousComponent;
    delete lastComponent.previousComponent;
    lastComponent = nextComponent;
  }
  components.reverse();
  let componentPos = 0,
      componentLen = components.length,
      newPos = 0,
      oldPos = 0;
  for (; componentPos < componentLen; componentPos++) {
    let component = components[componentPos];
    if (!component.removed) {
      if (!component.added && useLongestToken) {
        let value = newString.slice(newPos, newPos + component.count);
        value = value.map(function(value, i) {
          let oldValue = oldString[oldPos + i];
          return oldValue.length > value.length ? oldValue : value;
        });
        component.value = diff.join(value);
      } else {
        component.value = diff.join(newString.slice(newPos, newPos + component.count));
      }
      newPos += component.count;
      if (!component.added) {
        oldPos += component.count;
      }
    } else {
      component.value = diff.join(oldString.slice(oldPos, oldPos + component.count));
      oldPos += component.count;
      if (componentPos && components[componentPos - 1].added) {
        let tmp = components[componentPos - 1];
        components[componentPos - 1] = components[componentPos];
        components[componentPos] = tmp;
      }
    }
  }
  let finalComponent = components[componentLen - 1];
  if (componentLen > 1
      && typeof finalComponent.value === 'string'
      && (finalComponent.added || finalComponent.removed)
      && diff.equals('', finalComponent.value)) {
    components[componentLen - 2].value += finalComponent.value;
    components.pop();
  }
  return components;
}

const lineDiff = new Diff();
lineDiff.tokenize = function(value) {
  if(this.options.stripTrailingCr) {
    value = value.replace(/\r\n/g, '\n');
  }
  let retLines = [],
      linesAndNewlines = value.split(/(\n|\r\n)/);
  if (!linesAndNewlines[linesAndNewlines.length - 1]) {
    linesAndNewlines.pop();
  }
  for (let i = 0; i < linesAndNewlines.length; i++) {
    let line = linesAndNewlines[i];
    if (i % 2 && !this.options.newlineIsToken) {
      retLines[retLines.length - 1] += line;
    } else {
      if (this.options.ignoreWhitespace) {
        line = line.trim();
      }
      retLines.push(line);
    }
  }
  return retLines;
};
function diffLines(oldStr, newStr, callback) { return lineDiff.diff(oldStr, newStr, callback); }

function structuredPatch(oldFileName, newFileName, oldStr, newStr, oldHeader, newHeader, options) {
  if (!options) {
    options = {};
  }
  if (typeof options.context === 'undefined') {
    options.context = 4;
  }
  const diff = diffLines(oldStr, newStr, options);
  if(!diff) {
    return;
  }
  diff.push({value: '', lines: []});
  function contextLines(lines) {
    return lines.map(function(entry) { return ' ' + entry; });
  }
  let hunks = [];
  let oldRangeStart = 0, newRangeStart = 0, curRange = [],
      oldLine = 1, newLine = 1;
  for (let i = 0; i < diff.length; i++) {
    const current = diff[i],
          lines = current.lines || current.value.replace(/\n$/, '').split('\n');
    current.lines = lines;
    if (current.added || current.removed) {
      if (!oldRangeStart) {
        const prev = diff[i - 1];
        oldRangeStart = oldLine;
        newRangeStart = newLine;
        if (prev) {
          curRange = options.context > 0 ? contextLines(prev.lines.slice(-options.context)) : [];
          oldRangeStart -= curRange.length;
          newRangeStart -= curRange.length;
        }
      }
      curRange.push(... lines.map(function(entry) {
        return (current.added ? '+' : '-') + entry;
      }));
      if (current.added) {
        newLine += lines.length;
      } else {
        oldLine += lines.length;
      }
    } else {
      if (oldRangeStart) {
        if (lines.length <= options.context * 2 && i < diff.length - 2) {
          curRange.push(... contextLines(lines));
        } else {
          let contextSize = Math.min(lines.length, options.context);
          curRange.push(... contextLines(lines.slice(0, contextSize)));
          let hunk = {
            oldStart: oldRangeStart,
            oldLines: (oldLine - oldRangeStart + contextSize),
            newStart: newRangeStart,
            newLines: (newLine - newRangeStart + contextSize),
            lines: curRange
          };
          if (i >= diff.length - 2 && lines.length <= options.context) {
            let oldEOFNewline = ((/\n$/).test(oldStr));
            let newEOFNewline = ((/\n$/).test(newStr));
            let noNlBeforeAdds = lines.length == 0 && curRange.length > hunk.oldLines;
            if (!oldEOFNewline && noNlBeforeAdds && oldStr.length > 0) {
              curRange.splice(hunk.oldLines, 0, '\\ No newline at end of file');
            }
            if ((!oldEOFNewline && !noNlBeforeAdds) || !newEOFNewline) {
              curRange.push('\\ No newline at end of file');
            }
          }
          hunks.push(hunk);
          oldRangeStart = 0;
          newRangeStart = 0;
          curRange = [];
        }
      }
      oldLine += lines.length;
      newLine += lines.length;
    }
  }
  return {
    oldFileName: oldFileName, newFileName: newFileName,
    oldHeader: oldHeader, newHeader: newHeader,
    hunks: hunks
  };
}

const DIFF_PATH_TAG = 'Diff-Path';
const CHECKSUM_TAG = 'Checksum';

/**
 * Type of diff change.
 */
const TypesOfChanges = {
    Add: 'a',
    Delete: 'd',
};

var commonjsGlobal = typeof globalThis !== 'undefined' ? globalThis : typeof window !== 'undefined' ? window : typeof global !== 'undefined' ? global : typeof self !== 'undefined' ? self : {};

function getDefaultExportFromCjs (x) {
	return x && x.__esModule && Object.prototype.hasOwnProperty.call(x, 'default') ? x['default'] : x;
}

var sha1 = {exports: {}};

function commonjsRequire(path) {
	throw new Error('Could not dynamically require "' + path + '". Please configure the dynamicRequireTargets or/and ignoreDynamicRequires option of @rollup/plugin-commonjs appropriately for this require call to work.');
}

var core = {exports: {}};

var hasRequiredCore;
function requireCore () {
	if (hasRequiredCore) return core.exports;
	hasRequiredCore = 1;
	(function (module, exports) {
(function (root, factory) {
			{
				module.exports = factory();
			}
		}(commonjsGlobal, function () {
			var CryptoJS = CryptoJS || (function (Math, undefined$1) {
			    var crypto;
			    if (typeof window !== 'undefined' && window.crypto) {
			        crypto = window.crypto;
			    }
			    if (typeof self !== 'undefined' && self.crypto) {
			        crypto = self.crypto;
			    }
			    if (typeof globalThis !== 'undefined' && globalThis.crypto) {
			        crypto = globalThis.crypto;
			    }
			    if (!crypto && typeof window !== 'undefined' && window.msCrypto) {
			        crypto = window.msCrypto;
			    }
			    if (!crypto && typeof commonjsGlobal !== 'undefined' && commonjsGlobal.crypto) {
			        crypto = commonjsGlobal.crypto;
			    }
			    if (!crypto && typeof commonjsRequire === 'function') {
			        try {
			            crypto = require('crypto');
			        } catch (err) {}
			    }
			    var cryptoSecureRandomInt = function () {
			        if (crypto) {
			            if (typeof crypto.getRandomValues === 'function') {
			                try {
			                    return crypto.getRandomValues(new Uint32Array(1))[0];
			                } catch (err) {}
			            }
			            if (typeof crypto.randomBytes === 'function') {
			                try {
			                    return crypto.randomBytes(4).readInt32LE();
			                } catch (err) {}
			            }
			        }
			        throw new Error('Native crypto module could not be used to get secure random number.');
			    };
			    var create = Object.create || (function () {
			        function F() {}
			        return function (obj) {
			            var subtype;
			            F.prototype = obj;
			            subtype = new F();
			            F.prototype = null;
			            return subtype;
			        };
			    }());
			    var C = {};
			    var C_lib = C.lib = {};
			    var Base = C_lib.Base = (function () {
			        return {
			            extend: function (overrides) {
			                var subtype = create(this);
			                if (overrides) {
			                    subtype.mixIn(overrides);
			                }
			                if (!subtype.hasOwnProperty('init') || this.init === subtype.init) {
			                    subtype.init = function () {
			                        subtype.$super.init.apply(this, arguments);
			                    };
			                }
			                subtype.init.prototype = subtype;
			                subtype.$super = this;
			                return subtype;
			            },
			            create: function () {
			                var instance = this.extend();
			                instance.init.apply(instance, arguments);
			                return instance;
			            },
			            init: function () {
			            },
			            mixIn: function (properties) {
			                for (var propertyName in properties) {
			                    if (properties.hasOwnProperty(propertyName)) {
			                        this[propertyName] = properties[propertyName];
			                    }
			                }
			                if (properties.hasOwnProperty('toString')) {
			                    this.toString = properties.toString;
			                }
			            },
			            clone: function () {
			                return this.init.prototype.extend(this);
			            }
			        };
			    }());
			    var WordArray = C_lib.WordArray = Base.extend({
			        init: function (words, sigBytes) {
			            words = this.words = words || [];
			            if (sigBytes != undefined$1) {
			                this.sigBytes = sigBytes;
			            } else {
			                this.sigBytes = words.length * 4;
			            }
			        },
			        toString: function (encoder) {
			            return (encoder || Hex).stringify(this);
			        },
			        concat: function (wordArray) {
			            var thisWords = this.words;
			            var thatWords = wordArray.words;
			            var thisSigBytes = this.sigBytes;
			            var thatSigBytes = wordArray.sigBytes;
			            this.clamp();
			            if (thisSigBytes % 4) {
			                for (var i = 0; i < thatSigBytes; i++) {
			                    var thatByte = (thatWords[i >>> 2] >>> (24 - (i % 4) * 8)) & 0xff;
			                    thisWords[(thisSigBytes + i) >>> 2] |= thatByte << (24 - ((thisSigBytes + i) % 4) * 8);
			                }
			            } else {
			                for (var j = 0; j < thatSigBytes; j += 4) {
			                    thisWords[(thisSigBytes + j) >>> 2] = thatWords[j >>> 2];
			                }
			            }
			            this.sigBytes += thatSigBytes;
			            return this;
			        },
			        clamp: function () {
			            var words = this.words;
			            var sigBytes = this.sigBytes;
			            words[sigBytes >>> 2] &= 0xffffffff << (32 - (sigBytes % 4) * 8);
			            words.length = Math.ceil(sigBytes / 4);
			        },
			        clone: function () {
			            var clone = Base.clone.call(this);
			            clone.words = this.words.slice(0);
			            return clone;
			        },
			        random: function (nBytes) {
			            var words = [];
			            for (var i = 0; i < nBytes; i += 4) {
			                words.push(cryptoSecureRandomInt());
			            }
			            return new WordArray.init(words, nBytes);
			        }
			    });
			    var C_enc = C.enc = {};
			    var Hex = C_enc.Hex = {
			        stringify: function (wordArray) {
			            var words = wordArray.words;
			            var sigBytes = wordArray.sigBytes;
			            var hexChars = [];
			            for (var i = 0; i < sigBytes; i++) {
			                var bite = (words[i >>> 2] >>> (24 - (i % 4) * 8)) & 0xff;
			                hexChars.push((bite >>> 4).toString(16));
			                hexChars.push((bite & 0x0f).toString(16));
			            }
			            return hexChars.join('');
			        },
			        parse: function (hexStr) {
			            var hexStrLength = hexStr.length;
			            var words = [];
			            for (var i = 0; i < hexStrLength; i += 2) {
			                words[i >>> 3] |= parseInt(hexStr.substr(i, 2), 16) << (24 - (i % 8) * 4);
			            }
			            return new WordArray.init(words, hexStrLength / 2);
			        }
			    };
			    var Latin1 = C_enc.Latin1 = {
			        stringify: function (wordArray) {
			            var words = wordArray.words;
			            var sigBytes = wordArray.sigBytes;
			            var latin1Chars = [];
			            for (var i = 0; i < sigBytes; i++) {
			                var bite = (words[i >>> 2] >>> (24 - (i % 4) * 8)) & 0xff;
			                latin1Chars.push(String.fromCharCode(bite));
			            }
			            return latin1Chars.join('');
			        },
			        parse: function (latin1Str) {
			            var latin1StrLength = latin1Str.length;
			            var words = [];
			            for (var i = 0; i < latin1StrLength; i++) {
			                words[i >>> 2] |= (latin1Str.charCodeAt(i) & 0xff) << (24 - (i % 4) * 8);
			            }
			            return new WordArray.init(words, latin1StrLength);
			        }
			    };
			    var Utf8 = C_enc.Utf8 = {
			        stringify: function (wordArray) {
			            try {
			                return decodeURIComponent(escape(Latin1.stringify(wordArray)));
			            } catch (e) {
			                throw new Error('Malformed UTF-8 data');
			            }
			        },
			        parse: function (utf8Str) {
			            return Latin1.parse(unescape(encodeURIComponent(utf8Str)));
			        }
			    };
			    var BufferedBlockAlgorithm = C_lib.BufferedBlockAlgorithm = Base.extend({
			        reset: function () {
			            this._data = new WordArray.init();
			            this._nDataBytes = 0;
			        },
			        _append: function (data) {
			            if (typeof data == 'string') {
			                data = Utf8.parse(data);
			            }
			            this._data.concat(data);
			            this._nDataBytes += data.sigBytes;
			        },
			        _process: function (doFlush) {
			            var processedWords;
			            var data = this._data;
			            var dataWords = data.words;
			            var dataSigBytes = data.sigBytes;
			            var blockSize = this.blockSize;
			            var blockSizeBytes = blockSize * 4;
			            var nBlocksReady = dataSigBytes / blockSizeBytes;
			            if (doFlush) {
			                nBlocksReady = Math.ceil(nBlocksReady);
			            } else {
			                nBlocksReady = Math.max((nBlocksReady | 0) - this._minBufferSize, 0);
			            }
			            var nWordsReady = nBlocksReady * blockSize;
			            var nBytesReady = Math.min(nWordsReady * 4, dataSigBytes);
			            if (nWordsReady) {
			                for (var offset = 0; offset < nWordsReady; offset += blockSize) {
			                    this._doProcessBlock(dataWords, offset);
			                }
			                processedWords = dataWords.splice(0, nWordsReady);
			                data.sigBytes -= nBytesReady;
			            }
			            return new WordArray.init(processedWords, nBytesReady);
			        },
			        clone: function () {
			            var clone = Base.clone.call(this);
			            clone._data = this._data.clone();
			            return clone;
			        },
			        _minBufferSize: 0
			    });
			    C_lib.Hasher = BufferedBlockAlgorithm.extend({
			        cfg: Base.extend(),
			        init: function (cfg) {
			            this.cfg = this.cfg.extend(cfg);
			            this.reset();
			        },
			        reset: function () {
			            BufferedBlockAlgorithm.reset.call(this);
			            this._doReset();
			        },
			        update: function (messageUpdate) {
			            this._append(messageUpdate);
			            this._process();
			            return this;
			        },
			        finalize: function (messageUpdate) {
			            if (messageUpdate) {
			                this._append(messageUpdate);
			            }
			            var hash = this._doFinalize();
			            return hash;
			        },
			        blockSize: 512/32,
			        _createHelper: function (hasher) {
			            return function (message, cfg) {
			                return new hasher.init(cfg).finalize(message);
			            };
			        },
			        _createHmacHelper: function (hasher) {
			            return function (message, key) {
			                return new C_algo.HMAC.init(hasher, key).finalize(message);
			            };
			        }
			    });
			    var C_algo = C.algo = {};
			    return C;
			}(Math));
			return CryptoJS;
		}));
	} (core));
	return core.exports;
}

(function (module, exports) {
(function (root, factory) {
		{
			module.exports = factory(requireCore());
		}
	}(commonjsGlobal, function (CryptoJS) {
		(function () {
		    var C = CryptoJS;
		    var C_lib = C.lib;
		    var WordArray = C_lib.WordArray;
		    var Hasher = C_lib.Hasher;
		    var C_algo = C.algo;
		    var W = [];
		    var SHA1 = C_algo.SHA1 = Hasher.extend({
		        _doReset: function () {
		            this._hash = new WordArray.init([
		                0x67452301, 0xefcdab89,
		                0x98badcfe, 0x10325476,
		                0xc3d2e1f0
		            ]);
		        },
		        _doProcessBlock: function (M, offset) {
		            var H = this._hash.words;
		            var a = H[0];
		            var b = H[1];
		            var c = H[2];
		            var d = H[3];
		            var e = H[4];
		            for (var i = 0; i < 80; i++) {
		                if (i < 16) {
		                    W[i] = M[offset + i] | 0;
		                } else {
		                    var n = W[i - 3] ^ W[i - 8] ^ W[i - 14] ^ W[i - 16];
		                    W[i] = (n << 1) | (n >>> 31);
		                }
		                var t = ((a << 5) | (a >>> 27)) + e + W[i];
		                if (i < 20) {
		                    t += ((b & c) | (~b & d)) + 0x5a827999;
		                } else if (i < 40) {
		                    t += (b ^ c ^ d) + 0x6ed9eba1;
		                } else if (i < 60) {
		                    t += ((b & c) | (b & d) | (c & d)) - 0x70e44324;
		                } else  {
		                    t += (b ^ c ^ d) - 0x359d3e2a;
		                }
		                e = d;
		                d = c;
		                c = (b << 30) | (b >>> 2);
		                b = a;
		                a = t;
		            }
		            H[0] = (H[0] + a) | 0;
		            H[1] = (H[1] + b) | 0;
		            H[2] = (H[2] + c) | 0;
		            H[3] = (H[3] + d) | 0;
		            H[4] = (H[4] + e) | 0;
		        },
		        _doFinalize: function () {
		            var data = this._data;
		            var dataWords = data.words;
		            var nBitsTotal = this._nDataBytes * 8;
		            var nBitsLeft = data.sigBytes * 8;
		            dataWords[nBitsLeft >>> 5] |= 0x80 << (24 - nBitsLeft % 32);
		            dataWords[(((nBitsLeft + 64) >>> 9) << 4) + 14] = Math.floor(nBitsTotal / 0x100000000);
		            dataWords[(((nBitsLeft + 64) >>> 9) << 4) + 15] = nBitsTotal;
		            data.sigBytes = dataWords.length * 4;
		            this._process();
		            return this._hash;
		        },
		        clone: function () {
		            var clone = Hasher.clone.call(this);
		            clone._hash = this._hash.clone();
		            return clone;
		        }
		    });
		    C.SHA1 = Hasher._createHelper(SHA1);
		    C.HmacSHA1 = Hasher._createHmacHelper(SHA1);
		}());
		return CryptoJS.SHA1;
	}));
} (sha1));
var sha1Exports = sha1.exports;
var SHA1 = getDefaultExportFromCjs(sha1Exports);

var md5 = {exports: {}};

(function (module, exports) {
(function (root, factory) {
		{
			module.exports = factory(requireCore());
		}
	}(commonjsGlobal, function (CryptoJS) {
		(function (Math) {
		    var C = CryptoJS;
		    var C_lib = C.lib;
		    var WordArray = C_lib.WordArray;
		    var Hasher = C_lib.Hasher;
		    var C_algo = C.algo;
		    var T = [];
		    (function () {
		        for (var i = 0; i < 64; i++) {
		            T[i] = (Math.abs(Math.sin(i + 1)) * 0x100000000) | 0;
		        }
		    }());
		    var MD5 = C_algo.MD5 = Hasher.extend({
		        _doReset: function () {
		            this._hash = new WordArray.init([
		                0x67452301, 0xefcdab89,
		                0x98badcfe, 0x10325476
		            ]);
		        },
		        _doProcessBlock: function (M, offset) {
		            for (var i = 0; i < 16; i++) {
		                var offset_i = offset + i;
		                var M_offset_i = M[offset_i];
		                M[offset_i] = (
		                    (((M_offset_i << 8)  | (M_offset_i >>> 24)) & 0x00ff00ff) |
		                    (((M_offset_i << 24) | (M_offset_i >>> 8))  & 0xff00ff00)
		                );
		            }
		            var H = this._hash.words;
		            var M_offset_0  = M[offset + 0];
		            var M_offset_1  = M[offset + 1];
		            var M_offset_2  = M[offset + 2];
		            var M_offset_3  = M[offset + 3];
		            var M_offset_4  = M[offset + 4];
		            var M_offset_5  = M[offset + 5];
		            var M_offset_6  = M[offset + 6];
		            var M_offset_7  = M[offset + 7];
		            var M_offset_8  = M[offset + 8];
		            var M_offset_9  = M[offset + 9];
		            var M_offset_10 = M[offset + 10];
		            var M_offset_11 = M[offset + 11];
		            var M_offset_12 = M[offset + 12];
		            var M_offset_13 = M[offset + 13];
		            var M_offset_14 = M[offset + 14];
		            var M_offset_15 = M[offset + 15];
		            var a = H[0];
		            var b = H[1];
		            var c = H[2];
		            var d = H[3];
		            a = FF(a, b, c, d, M_offset_0,  7,  T[0]);
		            d = FF(d, a, b, c, M_offset_1,  12, T[1]);
		            c = FF(c, d, a, b, M_offset_2,  17, T[2]);
		            b = FF(b, c, d, a, M_offset_3,  22, T[3]);
		            a = FF(a, b, c, d, M_offset_4,  7,  T[4]);
		            d = FF(d, a, b, c, M_offset_5,  12, T[5]);
		            c = FF(c, d, a, b, M_offset_6,  17, T[6]);
		            b = FF(b, c, d, a, M_offset_7,  22, T[7]);
		            a = FF(a, b, c, d, M_offset_8,  7,  T[8]);
		            d = FF(d, a, b, c, M_offset_9,  12, T[9]);
		            c = FF(c, d, a, b, M_offset_10, 17, T[10]);
		            b = FF(b, c, d, a, M_offset_11, 22, T[11]);
		            a = FF(a, b, c, d, M_offset_12, 7,  T[12]);
		            d = FF(d, a, b, c, M_offset_13, 12, T[13]);
		            c = FF(c, d, a, b, M_offset_14, 17, T[14]);
		            b = FF(b, c, d, a, M_offset_15, 22, T[15]);
		            a = GG(a, b, c, d, M_offset_1,  5,  T[16]);
		            d = GG(d, a, b, c, M_offset_6,  9,  T[17]);
		            c = GG(c, d, a, b, M_offset_11, 14, T[18]);
		            b = GG(b, c, d, a, M_offset_0,  20, T[19]);
		            a = GG(a, b, c, d, M_offset_5,  5,  T[20]);
		            d = GG(d, a, b, c, M_offset_10, 9,  T[21]);
		            c = GG(c, d, a, b, M_offset_15, 14, T[22]);
		            b = GG(b, c, d, a, M_offset_4,  20, T[23]);
		            a = GG(a, b, c, d, M_offset_9,  5,  T[24]);
		            d = GG(d, a, b, c, M_offset_14, 9,  T[25]);
		            c = GG(c, d, a, b, M_offset_3,  14, T[26]);
		            b = GG(b, c, d, a, M_offset_8,  20, T[27]);
		            a = GG(a, b, c, d, M_offset_13, 5,  T[28]);
		            d = GG(d, a, b, c, M_offset_2,  9,  T[29]);
		            c = GG(c, d, a, b, M_offset_7,  14, T[30]);
		            b = GG(b, c, d, a, M_offset_12, 20, T[31]);
		            a = HH(a, b, c, d, M_offset_5,  4,  T[32]);
		            d = HH(d, a, b, c, M_offset_8,  11, T[33]);
		            c = HH(c, d, a, b, M_offset_11, 16, T[34]);
		            b = HH(b, c, d, a, M_offset_14, 23, T[35]);
		            a = HH(a, b, c, d, M_offset_1,  4,  T[36]);
		            d = HH(d, a, b, c, M_offset_4,  11, T[37]);
		            c = HH(c, d, a, b, M_offset_7,  16, T[38]);
		            b = HH(b, c, d, a, M_offset_10, 23, T[39]);
		            a = HH(a, b, c, d, M_offset_13, 4,  T[40]);
		            d = HH(d, a, b, c, M_offset_0,  11, T[41]);
		            c = HH(c, d, a, b, M_offset_3,  16, T[42]);
		            b = HH(b, c, d, a, M_offset_6,  23, T[43]);
		            a = HH(a, b, c, d, M_offset_9,  4,  T[44]);
		            d = HH(d, a, b, c, M_offset_12, 11, T[45]);
		            c = HH(c, d, a, b, M_offset_15, 16, T[46]);
		            b = HH(b, c, d, a, M_offset_2,  23, T[47]);
		            a = II(a, b, c, d, M_offset_0,  6,  T[48]);
		            d = II(d, a, b, c, M_offset_7,  10, T[49]);
		            c = II(c, d, a, b, M_offset_14, 15, T[50]);
		            b = II(b, c, d, a, M_offset_5,  21, T[51]);
		            a = II(a, b, c, d, M_offset_12, 6,  T[52]);
		            d = II(d, a, b, c, M_offset_3,  10, T[53]);
		            c = II(c, d, a, b, M_offset_10, 15, T[54]);
		            b = II(b, c, d, a, M_offset_1,  21, T[55]);
		            a = II(a, b, c, d, M_offset_8,  6,  T[56]);
		            d = II(d, a, b, c, M_offset_15, 10, T[57]);
		            c = II(c, d, a, b, M_offset_6,  15, T[58]);
		            b = II(b, c, d, a, M_offset_13, 21, T[59]);
		            a = II(a, b, c, d, M_offset_4,  6,  T[60]);
		            d = II(d, a, b, c, M_offset_11, 10, T[61]);
		            c = II(c, d, a, b, M_offset_2,  15, T[62]);
		            b = II(b, c, d, a, M_offset_9,  21, T[63]);
		            H[0] = (H[0] + a) | 0;
		            H[1] = (H[1] + b) | 0;
		            H[2] = (H[2] + c) | 0;
		            H[3] = (H[3] + d) | 0;
		        },
		        _doFinalize: function () {
		            var data = this._data;
		            var dataWords = data.words;
		            var nBitsTotal = this._nDataBytes * 8;
		            var nBitsLeft = data.sigBytes * 8;
		            dataWords[nBitsLeft >>> 5] |= 0x80 << (24 - nBitsLeft % 32);
		            var nBitsTotalH = Math.floor(nBitsTotal / 0x100000000);
		            var nBitsTotalL = nBitsTotal;
		            dataWords[(((nBitsLeft + 64) >>> 9) << 4) + 15] = (
		                (((nBitsTotalH << 8)  | (nBitsTotalH >>> 24)) & 0x00ff00ff) |
		                (((nBitsTotalH << 24) | (nBitsTotalH >>> 8))  & 0xff00ff00)
		            );
		            dataWords[(((nBitsLeft + 64) >>> 9) << 4) + 14] = (
		                (((nBitsTotalL << 8)  | (nBitsTotalL >>> 24)) & 0x00ff00ff) |
		                (((nBitsTotalL << 24) | (nBitsTotalL >>> 8))  & 0xff00ff00)
		            );
		            data.sigBytes = (dataWords.length + 1) * 4;
		            this._process();
		            var hash = this._hash;
		            var H = hash.words;
		            for (var i = 0; i < 4; i++) {
		                var H_i = H[i];
		                H[i] = (((H_i << 8)  | (H_i >>> 24)) & 0x00ff00ff) |
		                       (((H_i << 24) | (H_i >>> 8))  & 0xff00ff00);
		            }
		            return hash;
		        },
		        clone: function () {
		            var clone = Hasher.clone.call(this);
		            clone._hash = this._hash.clone();
		            return clone;
		        }
		    });
		    function FF(a, b, c, d, x, s, t) {
		        var n = a + ((b & c) | (~b & d)) + x + t;
		        return ((n << s) | (n >>> (32 - s))) + b;
		    }
		    function GG(a, b, c, d, x, s, t) {
		        var n = a + ((b & d) | (c & ~d)) + x + t;
		        return ((n << s) | (n >>> (32 - s))) + b;
		    }
		    function HH(a, b, c, d, x, s, t) {
		        var n = a + (b ^ c ^ d) + x + t;
		        return ((n << s) | (n >>> (32 - s))) + b;
		    }
		    function II(a, b, c, d, x, s, t) {
		        var n = a + (c ^ (b | ~d)) + x + t;
		        return ((n << s) | (n >>> (32 - s))) + b;
		    }
		    C.MD5 = Hasher._createHelper(MD5);
		    C.HmacMD5 = Hasher._createHmacHelper(MD5);
		}(Math));
		return CryptoJS.MD5;
	}));
} (md5));
var md5Exports = md5.exports;
var MD5 = getDefaultExportFromCjs(md5Exports);

var encBase64 = {exports: {}};

(function (module, exports) {
(function (root, factory) {
		{
			module.exports = factory(requireCore());
		}
	}(commonjsGlobal, function (CryptoJS) {
		(function () {
		    var C = CryptoJS;
		    var C_lib = C.lib;
		    var WordArray = C_lib.WordArray;
		    var C_enc = C.enc;
		    C_enc.Base64 = {
		        stringify: function (wordArray) {
		            var words = wordArray.words;
		            var sigBytes = wordArray.sigBytes;
		            var map = this._map;
		            wordArray.clamp();
		            var base64Chars = [];
		            for (var i = 0; i < sigBytes; i += 3) {
		                var byte1 = (words[i >>> 2]       >>> (24 - (i % 4) * 8))       & 0xff;
		                var byte2 = (words[(i + 1) >>> 2] >>> (24 - ((i + 1) % 4) * 8)) & 0xff;
		                var byte3 = (words[(i + 2) >>> 2] >>> (24 - ((i + 2) % 4) * 8)) & 0xff;
		                var triplet = (byte1 << 16) | (byte2 << 8) | byte3;
		                for (var j = 0; (j < 4) && (i + j * 0.75 < sigBytes); j++) {
		                    base64Chars.push(map.charAt((triplet >>> (6 * (3 - j))) & 0x3f));
		                }
		            }
		            var paddingChar = map.charAt(64);
		            if (paddingChar) {
		                while (base64Chars.length % 4) {
		                    base64Chars.push(paddingChar);
		                }
		            }
		            return base64Chars.join('');
		        },
		        parse: function (base64Str) {
		            var base64StrLength = base64Str.length;
		            var map = this._map;
		            var reverseMap = this._reverseMap;
		            if (!reverseMap) {
		                    reverseMap = this._reverseMap = [];
		                    for (var j = 0; j < map.length; j++) {
		                        reverseMap[map.charCodeAt(j)] = j;
		                    }
		            }
		            var paddingChar = map.charAt(64);
		            if (paddingChar) {
		                var paddingIndex = base64Str.indexOf(paddingChar);
		                if (paddingIndex !== -1) {
		                    base64StrLength = paddingIndex;
		                }
		            }
		            return parseLoop(base64Str, base64StrLength, reverseMap);
		        },
		        _map: 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/='
		    };
		    function parseLoop(base64Str, base64StrLength, reverseMap) {
		      var words = [];
		      var nBytes = 0;
		      for (var i = 0; i < base64StrLength; i++) {
		          if (i % 4) {
		              var bits1 = reverseMap[base64Str.charCodeAt(i - 1)] << ((i % 4) * 2);
		              var bits2 = reverseMap[base64Str.charCodeAt(i)] >>> (6 - (i % 4) * 2);
		              var bitsCombined = bits1 | bits2;
		              words[nBytes >>> 2] |= bitsCombined << (24 - (nBytes % 4) * 8);
		              nBytes++;
		          }
		      }
		      return WordArray.create(words, nBytes);
		    }
		}());
		return CryptoJS.enc.Base64;
	}));
} (encBase64));
var encBase64Exports = encBase64.exports;
var Base64 = getDefaultExportFromCjs(encBase64Exports);

/**
 * Calculates SHA1 checksum for patch.
 *
 * @param content Content to hash.
 *
 * @returns SHA1 checksum for patch.
 */
const calculateChecksumSHA1 = (content) => {
    const res = SHA1(content);
    return res.toString();
};
/**
 * Normalizes a message string by removing carriage return characters ('\r') and
 * replacing multiple newline characters ('\n') with a single newline character.
 * This function standardizes the format of newline characters in the message.
 *
 * @param content The string to normalize.
 *
 * @returns The normalized message with '\r' removed and consecutive '\n'
 * characters replaced with a single '\n'.
 */
const normalizeContent = (content) => {
    return content
        .replace(/\r/g, '')
        .replace(/\n+/g, '\n');
};
/**
 * Calculates the checksum of the given content using the MD5 hashing algorithm
 * and encodes it in Base64. It normalizes the content by removing carriage
 * returns and replacing multiple newlines with a single newline.
 * The checksum is then formatted with a trailing special comment identifier.
 * Trailing '=' characters in the Base64 encoded string are removed to match
 * the expected format.
 *
 * @see
 * {@link https://adblockplus.org/en/filters#special-comments Adblock Plus special comments}
 * {@link https://hg.adblockplus.org/adblockplus/file/tip/addChecksum.py Adblock Plus checksum script}
 *
 * @param content The content to hash.
 *
 * @returns The formatted checksum string.
 */
const calculateChecksumMD5 = (content) => {
    content = normalizeContent(content);
    const checksum = Base64.stringify(MD5(content));
    return checksum.trim().replace(/=+$/g, '');
};

/**
 * @file
 * This file describes how to work with the `diff` directive.
 *
 * Format:
 * ```
 * diff name:[name] checksum:[checksum] lines:[lines].
 * ```
 *
 * - `name`: Name of the corresponding filter list. Mandatory when a resource
 * name is specified in the list.
 * - `checksum`: The expected SHA1 checksum of the file after the patch
 * is applied. Used to validate the patch.
 * - `lines`: The number of lines that follow, making up the RCS diff block.
 * Line count is determined using the same algorithm as `wc -l`, counting
 * newline characters '\n'.
 *
 * The `diff` directive is optional. If not specified, the patch is applied without validation.
 *
 * @see @link [Diff Files Format](https://github.com/ameshkov/diffupdates?tab=readme-ov-file#diff-files-format)
 */
const DIFF_DIRECTIVE = 'diff';
const DIFF_DIRECTIVE_NAME = 'name';
const DIFF_DIRECTIVE_CHECKSUM = 'checksum';
const DIFF_DIRECTIVE_LINE = 'lines';
/**
 * Creates `diff` directive with `Diff-Name` from filter (if found) and with
 * checksum of the new filter and number of lines of the patch.
 *
 * @param oldDiffPathTag Diff-Path tag from old filter.
 * @param newFilterContent New filter content.
 * @param patchContent Patch content.
 *
 * @returns Created `diff` directive.
 */
const createDiffDirective = (oldDiffPathTag, newFilterContent, patchContent) => {
    const [, resourceName] = (oldDiffPathTag || '').split('#');
    const checksum = calculateChecksumSHA1(newFilterContent);
    const lines = patchContent.split('\n').length - 1;
    const directive = [DIFF_DIRECTIVE];
    if (resourceName) {
        directive.push(`${DIFF_DIRECTIVE_NAME}:${resourceName}`);
    }
    directive.push(`${DIFF_DIRECTIVE_CHECKSUM}:${checksum}`);
    directive.push(`${DIFF_DIRECTIVE_LINE}:${lines}`);
    return directive.join(' ');
};
/**
 * Parses a string to extract a Diff Directive object.
 *
 * @param s The string to parse.
 * @returns A Diff Directive object if the string is a valid diff directive,
 * otherwise null.
 */
const parseDiffDirective = (s) => {
    if (!s.startsWith(DIFF_DIRECTIVE)) {
        return null;
    }
    const parts = s
        .split(' ')
        // skip 'diff'
        .slice(1);
    const nameExists = parts[0].startsWith(DIFF_DIRECTIVE_NAME);
    if (nameExists) {
        return {
            name: parts[0].slice(`${DIFF_DIRECTIVE_NAME}:`.length),
            checksum: parts[1].slice(`${DIFF_DIRECTIVE_CHECKSUM}:`.length),
            lines: Number(parts[2].slice(`${DIFF_DIRECTIVE_LINE}:`.length)),
        };
    }
    return {
        checksum: parts[0].slice(`${DIFF_DIRECTIVE_CHECKSUM}:`.length),
        lines: Number(parts[1].slice(`${DIFF_DIRECTIVE_LINE}:`.length)),
    };
};

/* eslint-disable jsdoc/require-description-complete-sentence */
/**
 * @file
 * This file describes how to work with the patch file name.
 *
 * The Diff-Path also encodes additional information in the file name:
 *
 * <patchName>[-<resolution>]-<epochTimestamp>-<expirationPeriod>.patch[#<resourceName>]
 *
 * `patchName` - The name of the patch file, an arbitrary string to identify
 * the patch.
 * `epochTimestamp` - The epoch timestamp when the patch was generated (the unit
 * of that timestamp depends on the resolution, see below).
 * `expirationPeriod` - The expiration time for the diff update (the unit depends
 * on the resolution, see below).
 * `resolution` - An optional field that specifies the resolution for both
 * `expirationPeriod` and `epochTimestamp`. It can be either 'h' (hours),
 * 'm' (minutes), or 's' (seconds). If `resolution` is not specified,
 * it is assumed to be 'h'.
 * `resourceName` - The name of the resource that is being patched. This is used
 * to support batch updates, see the [Batch Updates](https://github.com/ameshkov/diffupdates?tab=readme-ov-file#batch-updates)
 * section for more details.
 *
 * @see {@link https://github.com/ameshkov/diffupdates?tab=readme-ov-file#-diff-path}
 */
/* eslint-enable jsdoc/require-description-complete-sentence */
/**
 * The file extension used for patch files.
 */
const FILE_EXTENSION = '.patch';
const MS_IN_SECONDS = 1000;
const MS_IN_MINUTES = MS_IN_SECONDS * 60;
const MS_IN_HOURS = MS_IN_MINUTES * 60;
/**
 * Enumeration representing different resolutions for timestamp generation.
 */
const Resolution = {
    Hours: 'h',
    Minutes: 'm',
    Seconds: 's',
};
/**
 * Throws an error for unexpected values.
 *
 * @param x The unexpected value.
 *
 * @throws Always throws an error with a message indicating an unexpected value.
 */
const assertNever = (x) => {
    throw new Error(`Unexpected value in resolution: ${x}`);
};
/**
 * Generates a creation time timestamp based on the specified resolution.
 *
 * @param resolution - The desired resolution for the timestamp (Minutes, Seconds,
 * or Hours).
 *
 * @returns A timestamp representing the creation time based on the specified
 * resolution.
 *
 * @throws {Error} If an unexpected resolution is provided.
 */
const generateCreationTime = (resolution) => {
    switch (resolution) {
        case Resolution.Hours:
            return Math.round(Date.now() / MS_IN_HOURS);
        case Resolution.Minutes:
            return Math.round(Date.now() / MS_IN_MINUTES);
        case Resolution.Seconds:
            return Math.round(Date.now() / MS_IN_SECONDS);
        default:
            return assertNever(resolution);
    }
};
/**
 * Converts a timestamp to milliseconds based on the specified resolution.
 *
 * @param timestamp The timestamp to convert.
 * @param resolution The desired resolution for the timestamp (Minutes, Seconds, or Hours).
 *
 * @returns The timestamp in milliseconds.
 *
 * @throws {Error} If an unexpected resolution is provided.
 */
const timestampWithResolutionToMs = (timestamp, resolution) => {
    switch (resolution) {
        case Resolution.Hours:
            return timestamp * MS_IN_HOURS;
        case Resolution.Minutes:
            return timestamp * MS_IN_MINUTES;
        case Resolution.Seconds:
            return timestamp * MS_IN_SECONDS;
        default:
            return assertNever(resolution);
    }
};
/**
 * Validates a patch name to ensure it contain only letters, digits, '_' and '.'.
 *
 * @param patchName The patch name to validate.
 *
 * @returns True if the patch name is valid, false otherwise.
 */
const isPatchNameValid = (patchName) => {
    return /^[a-zA-Z0-9_.]{1,64}$/.test(patchName);
};
const PATCH_FILE_ERROR_TEXT = "Name of the patch file should contain only letters, digits, '_' and '.'";
/**
 * Generates a patch name based on the provided options.
 *
 * @param options The options for creating the patch name.
 *
 * @returns A string representing the generated patch name.
 *
 * @throws {Error} If the provided name is invalid according to the criteria.
 */
const createPatchName = (options) => {
    const { name, resolution, time, } = options;
    if (!isPatchNameValid(name)) {
        throw new Error(PATCH_FILE_ERROR_TEXT);
    }
    const epochTimestamp = generateCreationTime(resolution);
    const newFilePatchName = [name];
    if (resolution && resolution !== Resolution.Hours) {
        newFilePatchName.push(resolution);
    }
    newFilePatchName.push(epochTimestamp.toString());
    newFilePatchName.push(time.toString());
    return newFilePatchName.join('-').concat(FILE_EXTENSION);
};
/**
 * Parses a patch name into its components.
 *
 * @param patchName - The patch name to parse.
 *
 * @returns An object containing the parsed components of the patch name.
 *
 * @throws Error if the patch name cannot be parsed.
 */
const parsePatchName = (patchName) => {
    const parts = patchName
        .slice(0, -FILE_EXTENSION.length)
        .split('-');
    // Long variant
    if (parts.length === 4) {
        const [name, parsedResolution, parsedEpochTimestamp, parsedTime,] = parts;
        if (!(Object.values(Resolution)).includes(parsedResolution)) {
            throw new Error(`Unrecognized resolution in patch name: ${patchName}`);
        }
        return {
            name,
            resolution: parsedResolution,
            epochTimestamp: Number.parseInt(parsedEpochTimestamp, 10),
            time: Number.parseInt(parsedTime, 10),
        };
    }
    // Short variant with a default resolution value
    if (parts.length === 3) {
        const [name, parsedEpochTimestamp, parsedTime,] = parts;
        const resolution = Resolution.Hours;
        return {
            name,
            resolution,
            epochTimestamp: Number.parseInt(parsedEpochTimestamp, 10),
            time: Number.parseInt(parsedTime, 10),
        };
    }
    throw new Error(`Cannot parse the patch name: ${patchName}`);
};

/**
 * Split a string by lines while preserving line breaks within the original lines.
 *
 * @param s The input string to split.
 *
 * @returns An array of strings where each element is a complete line of text,
 * including its line break.
 */
const splitByLines = (s) => {
    // It will save end of lines inside splitted strings.
    return s.split(/(?<=\r?\n)/);
};

/**
 * Creates a logger function with the specified "verbose" setting.
 *
 * @param verbose A flag indicating whether to output messages.
 *
 * @returns Function for logging messages.
 */
const createLogger = (verbose) => {
    return (message) => {
        if (verbose) {
            // eslint-disable-next-line no-console
            console.log(message);
        }
    };
};

// Lines of filter metadata to parse
const AMOUNT_OF_LINES_TO_PARSE = 50;
/**
 * Creates tag for filter list metadata.
 *
 * @param tagName Name of the tag.
 * @param value Value of the tag.
 * @param lineEnding Line ending to use in created tag.
 *
 * @returns Created tag in `! ${tagName}: ${value}` format.
 */
const createTag = (tagName, value, lineEnding) => {
    return `! ${tagName}: ${value}${lineEnding}`;
};
/**
 * Finds value of specified header tag in filter rules text.
 *
 * @param tagName Filter header tag name.
 * @param rules Lines of filter rules text.
 *
 * @returns Trimmed value of specified header tag or null if tag not found.
 */
const parseTag = (tagName, rules) => {
    // Look up no more than 50 first lines
    const maxLines = Math.min(AMOUNT_OF_LINES_TO_PARSE, rules.length);
    for (let i = 0; i < maxLines; i += 1) {
        const rule = rules[i];
        if (!rule) {
            continue;
        }
        const search = `! ${tagName}: `;
        const indexOfSearch = rule.indexOf(search);
        if (indexOfSearch >= 0) {
            return rule.substring(indexOfSearch + search.length).trim();
        }
    }
    return null;
};
/**
 * Removes a specified tag from an array of filter content strings.
 * This function searches for the first occurrence of the specified tag within
 * the array and removes the entire line containing that tag. If the tag is not
 * found, the array remains unchanged.
 *
 * @param tagName The name of the tag to be removed from the filter content.
 * @param filterContent An array of strings, each representing a line of filter content.
 *
 * @returns A new array of filter content with the specified tag removed.
 * If the tag is not found, the original array is returned unmodified.
 */
const removeTag = (tagName, filterContent) => {
    // Make copy of array to avoid mutation.
    const copy = filterContent.slice();
    // Cut first 50 lines to parse. We don't need to parse all file.
    const updatedFile = filterContent.slice(0, Math.min(AMOUNT_OF_LINES_TO_PARSE, filterContent.length));
    const tagIdx = updatedFile.findIndex((line) => line.includes(tagName));
    if (tagIdx >= 0) {
        copy.splice(tagIdx, 1);
    }
    return copy;
};

/**
 * Parses an RCS (Revision Control System) operation string into an object
 * containing operation details.
 *
 * @param rcsOperation The RCS operation string to parse.
 *
 * @returns An object with the parsed operation details.
 *
 * @throws Throws an error if the operation string is not valid.
 */
const parseRcsOperation = (rcsOperation) => {
    const [operationInfo, operationCounter] = rcsOperation.split(' ');
    const typeOfOperation = operationInfo[0];
    // Indexes in RCS are natural so we need to subtract 1.
    const startIndex = Number(operationInfo.slice(1)) - 1;
    const numberOfLines = Number(operationCounter);
    if (typeOfOperation !== TypesOfChanges.Add && typeOfOperation !== TypesOfChanges.Delete) {
        throw new Error(`Operation is not valid: cannot parse type: ${rcsOperation}`);
    }
    if (Number.isNaN(startIndex)) {
        throw new Error(`Operation is not valid: cannot parse index: ${rcsOperation}`);
    }
    if (Number.isNaN(numberOfLines)) {
        throw new Error(`Operation is not valid: cannot parse number of lines: ${rcsOperation}`);
    }
    return {
        typeOfOperation,
        startIndex,
        numberOfLines,
    };
};
/**
 * Applies an RCS (Revision Control System) patch to a filter content.
 *
 * @param filterContent An array of strings representing the original filter content.
 * @param patch An array of strings representing the RCS patch to apply.
 * @param checksum An optional checksum to validate the updated filter content.
 * @returns The updated filter content after applying the patch.
 * @throws If the provided checksum doesn't match the calculated checksum.
 */
const applyRcsPatch = (filterContent, patch, checksum) => {
    // Make a copy
    const lines = filterContent.slice();
    // NOTE: Note that the line indices start always refer to the text which is
    // transformed as it is in its original state, without taking the precending
    // changes into account, so we need to collect "virtual offset" between
    // "current changing" file and "old file".
    let currentOffset = 0;
    for (let index = 0; index < patch.length; index += 1) {
        const patchLine = patch[index];
        // Skip empty lines
        if (patchLine === '') {
            continue;
        }
        const parsedRcsOperation = parseRcsOperation(patchLine);
        const { typeOfOperation, startIndex, numberOfLines, } = parsedRcsOperation;
        const startIndexWithOffset = startIndex + currentOffset;
        if (typeOfOperation === TypesOfChanges.Delete) {
            lines.splice(startIndexWithOffset, numberOfLines);
            currentOffset -= numberOfLines;
        }
        if (typeOfOperation === TypesOfChanges.Add) {
            const stringsToAdd = [];
            let nStringsToAdd = numberOfLines;
            // Scan strings to add starting from the second line.
            let scanFrom = index + 1;
            while (nStringsToAdd > 0 && scanFrom < patch.length) {
                stringsToAdd.push(patch[scanFrom]);
                scanFrom += 1;
                nStringsToAdd -= 1;
            }
            index += stringsToAdd.length;
            if (startIndexWithOffset < 0) {
                lines.unshift(...stringsToAdd);
            }
            else if (startIndexWithOffset > lines.length) {
                lines.push(...stringsToAdd);
            }
            else {
                lines.splice(startIndexWithOffset + 1, 0, ...stringsToAdd);
            }
            currentOffset += numberOfLines;
        }
    }
    const updatedFilter = lines.join('');
    if (checksum) {
        const c = calculateChecksumSHA1(updatedFilter);
        if (c !== checksum) {
            throw new Error('Checksums are not equal.');
        }
    }
    return updatedFilter;
};

/// <reference path="../../types/diff.d.ts" />
const DEFAULT_PATCH_TTL_SECONDS = 60 * 60 * 24 * 7;
const NEW_LINE_INFO = '\\ No newline at end of file';
let log;
const PATCH_EXTENSION = '.patch';
/**
 * Detects type of diff changes: add or delete.
 *
 * @param line Line of string to parse.
 *
 * @returns String type: 'Add' or 'Delete' or null if type cannot be parsed.
 */
const detectTypeOfChanges = (line) => {
    if (line.startsWith('+')) {
        return TypesOfChanges.Add;
    }
    if (line.startsWith('-')) {
        return TypesOfChanges.Delete;
    }
    return null;
};
/**
 * Creates patch in [RCS format](https://www.gnu.org/software/diffutils/manual/diffutils.html#RCS).
 *
 * @param oldFile Old file.
 * @param newFile New file.
 *
 * @returns Difference between old and new files in RCS format.
 */
const createPatch = (oldFile, newFile) => {
    const { hunks } = structuredPatch('oldFile', 'newFile', oldFile, newFile, '', '', {
        context: 0,
        ignoreCase: false,
    });
    const outDiff = [];
    let stringsToAdd = [];
    let nStringsToDelete = 0;
    const collectParsedDiffBlock = (curIndex, deleted, added) => {
        if (deleted > 0) {
            const deleteFromPosition = curIndex;
            const rcsLines = [`d${deleteFromPosition} ${deleted}`];
            return rcsLines;
        }
        if (added.length > 0) {
            const addFromPosition = curIndex - 1;
            const rcsLines = [
                `a${addFromPosition} ${added.length}`,
                ...added,
            ];
            return rcsLines;
        }
        return [];
    };
    hunks.forEach((hunk, hunkIdx) => {
        const { oldStart, lines } = hunk;
        let fileIndexScanned = oldStart;
        // Library will print some debug info so we need to skip this line.
        const filteredLines = lines.filter((l) => l !== NEW_LINE_INFO);
        for (let index = 0; index < filteredLines.length; index += 1) {
            const line = filteredLines[index];
            // Detect type of diff operation
            const typeOfChange = detectTypeOfChanges(line);
            // Library will print some debug info so we need to skip this line.
            if (typeOfChange === null) {
                throw new Error(`Cannot parse line: ${line}`);
            }
            if (typeOfChange === TypesOfChanges.Delete) {
                // In RCS format we don't need content of deleted string.
                nStringsToDelete += 1;
            }
            if (typeOfChange === TypesOfChanges.Add) {
                // Slice "+" from the start of string.
                stringsToAdd.push(line.slice(1));
            }
            // Check type of next line for possible change diff type from 'add'
            // to 'delete' or from 'delete' to 'add'.
            const nextLineTypeOfChange = index + 1 < filteredLines.length
                ? detectTypeOfChanges(filteredLines[index + 1])
                : null;
            // If type will change - save current block
            const typeWillChangeOnNextLine = nextLineTypeOfChange && typeOfChange !== nextLineTypeOfChange;
            // Or if current line is the last - we need to save collected info.
            const isLastLine = index === filteredLines.length - 1;
            if (typeWillChangeOnNextLine || isLastLine) {
                const diffRCSLines = collectParsedDiffBlock(fileIndexScanned, nStringsToDelete, stringsToAdd);
                outDiff.push(...diffRCSLines);
                // Drop counters
                nStringsToDelete = 0;
                stringsToAdd = [];
                // Move scanned index
                fileIndexScanned += index + 1;
            }
        }
        // Check if we need to insert new line to the patch or not
        if ((lines.filter((l) => l === NEW_LINE_INFO).length > 0 && lines[lines.length - 1] !== NEW_LINE_INFO)
            || (lines.filter((l) => l === NEW_LINE_INFO).length === 0 && hunkIdx === hunks.length - 1)) {
            outDiff[outDiff.length - 1] = outDiff[outDiff.length - 1].concat('\n');
        }
    });
    return outDiff.join('\n');
};
/**
 * Scans `absolutePatchesPath` for files with the "*.patch" pattern and deletes
 * those whose created epoch timestamp has expired and whose are not empty.
 *
 * @param absolutePatchesPath Directory for scan.
 * @param deleteOlderThanSeconds The time to live for the patch in *seconds*.
 *
 * @returns Returns number of deleted patches.
 */
const deleteOutdatedPatches = async (absolutePatchesPath, deleteOlderThanSeconds) => {
    const files = await fs.promises.readdir(absolutePatchesPath);
    const tasksToDeleteFiles = [];
    for (const file of files) {
        if (!file.endsWith(PATCH_EXTENSION)) {
            log(`Skipped deleting file "${file}" because its extension is not "${PATCH_EXTENSION}"`);
            continue;
        }
        const filePath = path.join(absolutePatchesPath, file);
        // eslint-disable-next-line no-await-in-loop
        const { size } = await fs.promises.stat(filePath);
        // If size is 0 - it means, that this patch is last active and we cannot
        // delete it even if it is outdated, because there is active link to
        // this patch in the filter's Diff-Path tag.
        if (size === 0) {
            log(`Skipped deleting file "${file}" because it is empty.`);
            continue;
        }
        const { resolution, epochTimestamp, } = parsePatchName(file);
        const createdMs = timestampWithResolutionToMs(epochTimestamp, resolution);
        const deleteOlderThanMs = deleteOlderThanSeconds * 1000;
        const deleteOlderThanDateMs = new Date().getTime() - deleteOlderThanMs;
        if (createdMs < deleteOlderThanDateMs) {
            log(`Deleting "${file}".`);
            // eslint-disable-next-line no-await-in-loop
            tasksToDeleteFiles.push(fs.promises.rm(filePath));
        }
        else {
            log(`Timestamp of "${file}" has not expired, deleting is skipped.`);
        }
    }
    const deleted = await Promise.all(tasksToDeleteFiles);
    return deleted.length;
};
/**
 * Checks if the provided file content contains a checksum tag within its first 200 characters.
 * This approach is selected to exclude parsing checksums from included filters.
 *
 * @param file The file content as a string.
 *
 * @returns `true` if the checksum tag is found, otherwise `false`.
 */
const hasChecksum = (file) => {
    const partOfFile = file.substring(0, 200);
    const lines = splitByLines(partOfFile);
    return lines.some((line) => line.startsWith(`! ${CHECKSUM_TAG}`));
};
/**
 * Updates the 'Diff-Path' tag and optionally recalculates and adds a new
 * checksum tag in a provided array of filter lines.
 *
 * @param filterContent Filter content that needs to be updated.
 * @param diffPathTagValue The new value to be set for the 'Diff-Path' tag.
 *
 * @returns Updated filter content.
 */
const updateTags = (filterContent, diffPathTagValue) => {
    // Split the content of the filters into lines.
    let newFileSplitted = splitByLines(filterContent);
    let userAgent;
    // User agent tag.
    if (newFileSplitted[0].startsWith('![') || newFileSplitted[0].startsWith('[')) {
        userAgent = newFileSplitted.shift();
    }
    // Remove tags 'Diff-Path' and 'Checksum' from new filterContent.
    newFileSplitted = removeTag(DIFF_PATH_TAG, removeTag(CHECKSUM_TAG, newFileSplitted));
    const lineEnding = newFileSplitted[0].endsWith('\r\n') ? '\r\n' : '\n';
    const diffPath = createTag(DIFF_PATH_TAG, diffPathTagValue, lineEnding);
    newFileSplitted.unshift(diffPath);
    if (userAgent !== undefined) {
        newFileSplitted.unshift(userAgent);
    }
    // If filter had checksum, calculate and insert a new checksum tag at the start of the filter
    if (hasChecksum(filterContent)) {
        const updatedChecksum = calculateChecksumMD5(newFileSplitted.join(''));
        const checksumTag = createTag(CHECKSUM_TAG, updatedChecksum, lineEnding);
        if (userAgent !== undefined) {
            // Insert Checksum after the userAgent header.
            newFileSplitted.splice(1, 0, checksumTag);
        }
        else {
            newFileSplitted.unshift(checksumTag);
        }
    }
    return newFileSplitted.join('');
};
/**
 * Validates a patch by comparing the old file with the new file after applying the patch.
 *
 * @param oldFile The original file content as a string.
 * @param newFile The expected file content after the patch is applied.
 * @param patch The patch content as a string.
 *
 * @returns Returns true if the patched old file matches the new file, false otherwise.
 */
const isPatchValid = (oldFile, newFile, patch) => {
    const patchLines = splitByLines(patch);
    const diffDirective = parseDiffDirective(patchLines[0]);
    const updatedFile = applyRcsPatch(splitByLines(oldFile), diffDirective ? patchLines.slice(1) : patchLines, diffDirective ? diffDirective.checksum : undefined);
    return updatedFile === newFile;
};
/**
 * Determines if there are significant changes between two files, excluding
 * changes in 'Checksum' and 'Diff-Path' tags.
 * The function splits the file contents into lines, removes the mentioned tags,
 * and then compares the contents to determine if there are meaningful changes.
 *
 * @param oldFile The content of the old file as a string.
 * @param newFile The content of the new file as a string.
 *
 * @returns `true` if there are significant changes, otherwise `false`.
 */
const hasChanges = (oldFile, newFile) => {
    // Split the content of the filters into lines.
    let oldFileSplitted = splitByLines(oldFile);
    let newFileSplitted = splitByLines(newFile);
    // Remove 'Checksum' and 'Diff-Path' tags from both old and new filters.
    oldFileSplitted = removeTag(DIFF_PATH_TAG, removeTag(CHECKSUM_TAG, oldFileSplitted));
    newFileSplitted = removeTag(DIFF_PATH_TAG, removeTag(CHECKSUM_TAG, newFileSplitted));
    const oldFileHasChecksum = hasChecksum(oldFile);
    const newFileHasChecksum = hasChecksum(newFile);
    // Determine if there are meaningful changes in the files, excluding the 'Diff-Path' and 'Checksum' tags.
    // This comparison considers both the content and the presence of checksum tags in the old and new files.
    if (oldFileSplitted.join('') === newFileSplitted.join('') && oldFileHasChecksum === newFileHasChecksum) {
        return false;
    }
    return true;
};
/**
 * Asynchronously updates the 'Diff-Path' tag in a new filter file and creates
 * a diff patch compared to an old file.
 * This function ensures that changes to 'Diff-Path' and 'Checksum' are correctly
 * included in the diff patch.
 * It throws an error if the old and new patch names are the same.
 *
 * @param oldFile The content of the old file as a string.
 * @param newFile The content of the new file as a string.
 * @param checksumFlag Flag to determine if a checksum should be added to the patch.
 * @param pathToPatchesRelativeToNewFilter The relative path to the patches directory from the new filter's location.
 * @param newFilePatchName The proposed diff name for the new file.
 * @param oldFilePatchName The diff name in the old file, or null if not present.
 *
 * @throws Error if the old and new patch names are the same.
 *
 * @returns A promise that resolves to an object containing the updated content
 * of the new file and the generated diff patch.
 */
const updateFileAndCreatePatch = async (oldFile, newFile, checksumFlag, pathToPatchesRelativeToNewFilter, newFilePatchName, oldFilePatchName) => {
    // Verify that the patch names are not the same.
    if (oldFilePatchName === newFilePatchName) {
        // eslint-disable-next-line max-len
        throw new Error(`The old patch name "${oldFilePatchName}" and the new patch name "${newFilePatchName}" are the same. Consider changing the unit of measure or waiting.`);
    }
    // Note: Update 'Diff-Path' and 'Checksum' before calculating the diff
    // to ensure their changes are included in the resulting diff patch.
    const newFilterDiffPathTagValue = path.join(pathToPatchesRelativeToNewFilter, newFilePatchName);
    const newFileWithUpdatedTags = updateTags(newFile, newFilterDiffPathTagValue);
    // Generate the diff patch.
    let patch = createPatch(oldFile, newFileWithUpdatedTags);
    // Optionally add a checksum to the patch.
    if (checksumFlag) {
        const diffDirective = createDiffDirective(oldFilePatchName, newFileWithUpdatedTags, patch);
        patch = diffDirective.concat('\n', patch);
    }
    return {
        newFileWithUpdatedTags,
        patch,
    };
};
/**
 * Asynchronously builds a diff between two filter files and handles related
 * file operations. Resolves paths, creates necessary folders, deletes outdated
 * patches, and checks for changes in filter content.
 * If there are changes other than those with 'Diff-Path' and 'Checksum' tags,
 * it updates the content of the new filter file with new 'Diff-Path'
 * and 'Checksum' tags and creates patch files accordingly.
 *
 * @param params The parameters including paths, resolution, and other settings
 * for diff generation.
 *
 * @returns A promise that resolves when the diff operation is complete.
 */
const buildDiff = async (params) => {
    const { oldFilterPath, newFilterPath, patchesPath, name, time, resolution = Resolution.Hours, checksum: checksumFlag = false, deleteOlderThanSec = DEFAULT_PATCH_TTL_SECONDS, verbose = false, } = params;
    log = createLogger(verbose);
    // Resolve all necessary paths.
    const absoluteOldListPath = path.resolve(process.cwd(), oldFilterPath);
    const absoluteNewListPath = path.resolve(process.cwd(), newFilterPath);
    const absolutePatchesPath = path.resolve(process.cwd(), patchesPath);
    const pathToPatchesRelativeToNewFilter = path.relative(path.dirname(newFilterPath), absolutePatchesPath);
    log(`Checking diff between "${absoluteOldListPath}" and "${absoluteNewListPath}".`);
    log(`Path to patches: "${absolutePatchesPath}".`);
    // Create the patches folder if it doesn't exist.
    if (!fs.existsSync(absolutePatchesPath)) {
        await fs.promises.mkdir(absolutePatchesPath, { recursive: true });
        log(`Created missing patches folder at "${absolutePatchesPath}".`);
    }
    log(`Checking patches to delete in the patches folder: "${absolutePatchesPath}"`);
    // Scan the patches folder and delete outdated patches.
    const deleted = await deleteOutdatedPatches(absolutePatchesPath, deleteOlderThanSec);
    if (deleted > 0) {
        log(`Deleted ${deleted} outdated patches from "${absolutePatchesPath}".`);
    }
    // Read the content of the filters.
    const oldFile = await fs.promises.readFile(absoluteOldListPath, { encoding: 'utf-8' });
    const newFile = await fs.promises.readFile(absoluteNewListPath, { encoding: 'utf-8' });
    // Check for any changes except changes with Diff-Path and Checksum
    // in the filters.
    if (!hasChanges(oldFile, newFile)) {
        // If no significant changes, undo removal of 'Diff-Path' (it happens
        // by run `compiler` which currently not supported `Diff-Path` tag and
        // always remove it, even if filter has not changes)
        // and save the old file content to the new file.
        await fs.promises.writeFile(absoluteNewListPath, oldFile);
        log('No significant changes found.');
        log(`Reverted any removal of 'Diff-Path' in the new filter "${absoluteNewListPath}".`);
        return;
    }
    // Retrieve and save the 'Diff-Path' tag from the old filter before removal.
    let oldFilePatchName = parseTag(DIFF_PATH_TAG, splitByLines(oldFile));
    // Remove resourceName part after "#" sign if it exists.
    oldFilePatchName = oldFilePatchName ? oldFilePatchName.split('#')[0] : null;
    // Generate a name for the new patch.
    const newFilePatchName = createPatchName({ name, resolution, time });
    const { newFileWithUpdatedTags, patch, } = await updateFileAndCreatePatch(oldFile, newFile, checksumFlag, pathToPatchesRelativeToNewFilter, newFilePatchName, oldFilePatchName);
    if (!isPatchValid(oldFile, newFileWithUpdatedTags, patch)) {
        log('Validating generated patch failed: old file with applied patch is not equal to new file.');
        return;
    }
    // Write the updated content to the new filter with an updated 'Diff-Path' and 'Checksum'.
    await fs.promises.writeFile(absoluteNewListPath, newFileWithUpdatedTags);
    log(`Updated 'Diff-Path' and 'Checksum' tags in the new filter at "${absoluteNewListPath}".`);
    // Create an empty patch for the future version if it doesn't exist.
    const emptyPatchForNewVersion = path.join(absolutePatchesPath, newFilePatchName);
    if (!fs.existsSync(emptyPatchForNewVersion)) {
        await fs.promises.writeFile(emptyPatchForNewVersion, '');
        log(`Created a patch for the new filter at ${emptyPatchForNewVersion}.`);
    }
    // If 'Diff-Path' is not found in the old filter, a patch for the old file
    // cannot be created.
    if (!oldFilePatchName) {
        log('No "Diff-Path" found in the old filter. Cannot create a patch for the old file.');
        return;
    }
    // 'Diff-Path' contains a path relative to the filter path, requiring path resolution.
    // Note: resolve this relative patch path to the new filter path to ensure
    // that folder with new filter will contain three main things: new filter itself,
    // patch to old version and new empty patch for future changes.
    const oldFilePatch = path.resolve(path.dirname(absoluteNewListPath), oldFilePatchName);
    // Save the diff to the patch file.
    await fs.promises.writeFile(oldFilePatch, patch);
    log(`Saved the patch to: ${oldFilePatch}`);
};

const DiffBuilder = {
    buildDiff,
};

exports.DiffBuilder = DiffBuilder;
exports.PATCH_EXTENSION = PATCH_EXTENSION;
